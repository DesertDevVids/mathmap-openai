-*- outline -*-

* INTRODUCTION

The proposed addition to the MathMap language is the ability to use MathMap
filters (formerly known as expressions) within other filters, i.e., making it
possible to nest filters.  The main syntactic addition is a syntax for
defining filters.

Let's look at a simple filter definition:

  filter flip_x (image input)
    input(xy * xy:[-1,1])
  end

It's pretty straightforward this far.  The difference in the actual expression
between the old MathMap and the new is that we don't use "origVal" any more,
but "call" the image directly to get a pixel.

This example is a bit more complex:

  filter blend (image i1, image i2, float alpha)
    {
      alpha : 0.0 - 1.0
    }
    i1(xy)*(1-alpha) + i2(xy)*alpha
  end

It operates on two images and takes an additional argument, the value range of
which we declare to be between 0 and 1.  This declaration is used only for the
user values system and will probably also include a documentation string for
the filter itself and the individual user values.

* NESTING

Now let's look at a filter which nests other filters:

  filter blend_flip (image input)
    blend(input, flip_x(input), 0.5, xy)
  end

This needs a bit of explanation.  We obviously use the "blend" filter to blend
the input image with another image, that image being "flip_x(input)", which
is, of course, the filter "flip_x" applied to the input image.

What's funny is that we pass "xy" to "blend", but not to "flip_x".  To
understand why this is the case, we must remember that the result of a MathMap
expression is a pixel, not an image.  Hence, what we define as a "filter"
actually only returns a single pixel, only it's called as often as is needed
to generate a whole image.

In the new MathMap language, however, it's also possible to obtain a new
"virtual" image by taking a filter and giving it it's input images and
arguments, but not telling it which pixel we want.  Afterwards, we can then
give coordinates to this virtual image to obtain the pixel at that position,
effectively calling the filter.  We can also pass the virtual image to another
filter, as if it were "real".

To get a pixel from a virtual image, we simply apply coordinates to it, like
with a real image, so we could actually also write the above filter as

  filter blend_flip (image input)
    (blend(input, flip_x(input), 0.5))(xy)
  end

Passing the coordinates directly to the filter is just syntactic sugar, so to
say.  Another way of seeing it is realizing that a filter actually takes an
additional implicit argument that we don't have to declare, namely xy, which
we can omit, resulting in a partial application of the filter, which is a
virtual image.

** Quality

One big advantage of having virtual images is that we don't lose information
as we would, would we render a real image for each application of a filter.
Consider the following example:

  filter zoom_in (image input)
    input(xy/2)
  end

  filter zoom_out (image input)
    input(xy*2)
  end

  filter identity1 (image input)
    zoom_in(zoom_out(input), xy)
  end

  filter identity2 (image input)
    zoom_out(zoom_in(input), xy)
  end

"identity1" first zooms out, then zooms in, while "identity2" does it the
other way around.

If we computed identity1 by first rendering an image with zoom_out applied,
and then applying zoom_in to that image, we'd get a blurred version of the
original image, since we'd be scaling up a scaled down version of the
original.

If, on the other hand, we computed identity2 the same way, we'd get a good
quality version of the inner quarter of the original image, the outer parts
blackened out (if that's the edge behaviour set).  By scaling up the original
image, we'd obviously lose the outer parts unless we'd make the temporary
up-scaled image four times as large as the original.  But how would MathMap
know that it's supposed to do that?

By not rendering these temporary images, however, MathMap would suffer neither
of these losses and the "identity1" filter, for example, would be equivalent
to

  filter identity1_inlined (image input)
    input(xy/2*2)
  end

In fact, the MathMap compiler might even be smart enough to perform that
inlining optimization, so there'd not even be calls to zoom_in and zoom_out.

** Forcing Rendering

Despite the quality advantage it is sometimes desirable to actually render the
temporary images, hence making them "real".  The most obvious reason for this
is efficiency.  Nesting filters becomes inefficient if a filter in the chain
needs more than one pixel from one of its input images to produce an output
pixel, because that means that some input pixels must be calculated more than
once.

Let's look at a somewhat realistic example.  One of the example filters of
MathMap is Conway's "Game of Life":

  filter life (image img)
    num=(gray(img(xy+xy:[-1,-1]))>0.5)+
        (gray(img(xy+xy:[-1,0]))>0.5)+
        (gray(img(xy+xy:[-1,1]))>0.5)+
        (gray(img(xy+xy:[0,-1]))>0.5)+
        (gray(img(xy+xy:[0,1]))>0.5)+
        (gray(img(xy+xy:[1,-1]))>0.5)+
        (gray(img(xy+xy:[1,0]))>0.5)+
        (gray(img(xy+xy:[1,1]))>0.5);
    val=gray(img(xy))>0.5;
    rgba:[0,0,0,1] + rgba:[1,1,1,0] * if num==2 then val
                                      else if num==3 then 1
                                      else 0 end end
  end

It looks a little awkward, but it works.  Now let's say we want to do more
than one step of this game, like this:

  filter life_3 (image img)
    life(life(life(img)), xy)
  end

For each output pixel, the outermost "life" calls the middle "life" 9 times,
which in its turn for each invocation calls the innermost "life" 9 times,
which for each invocation examines 9 pixels in the input image, i.e., we
examine 9*9*9 = 729 input pixels for one output pixel.  Obviously each further
nesting takes 9 times longer to calculate, which is clearly not necessary.

To solve this problem, we introduce a "render" function, which takes a virtual
image and renders it, producing a real image:

  filter life_3_fast (image img)
    life(render(life(render(life(render(img))))), xy)
  end

Notice that we render the input image as well, because it, too, might be a
virtual image.  Rendering a real image just returns that same image, so
there's no harm if it isn't.

This filter might seem very inefficient because
"render(life(render(life(render(img)))))" is called for each pixel that
"life_3_fast" has to calculate.  The MathMap compiler is, however, smart
enough to realize that that expression does not depend on "xy" and must hence
only be calculated once.  

* FILTERS AS FIRST CLASS VALUES

An even more far reaching extension, which would come cheap if we got this
far, is making even filters first class values, i.e., allowing the passing of
filters, not only images and virtual images, to other filters.

The only simple example I can think of right now is applying a filter multiple
times, which would look like this:

  filter do_often (image input, filter do_what (image input), int how_often)
    result = input;
    for i = 1 to how_often do
      result = do_what(result);
    end;
    result(xy)
  end

I've just invented the "for" syntax, which might be a good idea to add to
MathMap.
